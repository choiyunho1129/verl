{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen critique → Llama reward walkthrough\n",
        "\n",
        "이 노트북은 `examples/grpo_trainer/run_qwen2.5-7b_instruct_critique.sh` 흐름을 노트북 형태로 옮겨,\n",
        "1) Qwen2.5-7B-Instruct로 critique를 생성하고,\n",
        "2) vLLM으로 띄운 Llama reward 모델에 critique를 넣어 variant 문제를 풀고,\n",
        "3) 변형 문제별 정답률과 출력 내용을 확인하는 과정을 보여줍니다.\n",
        "\n",
        "GPU 자원이 필요하므로 실행 전 리소스를 확인하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5ba92d3d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: /data1/home/yunhochoi/verl\n",
            "Train file: /data1/home/yunhochoi/verl/data/train_critique.parquet\n",
            "Reward API: http://localhost:8000/v1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "# 경로 설정\n",
        "REPO_ROOT = Path.cwd().resolve()\n",
        "if not (REPO_ROOT / \"verl\").exists():\n",
        "    # 노트북 위치에 따라 repo root 탐색\n",
        "    candidates = []\n",
        "    if \"__file__\" in globals():\n",
        "        candidates.append(Path(__file__).resolve())\n",
        "    candidates.append(Path.cwd().resolve())\n",
        "    for base in candidates:\n",
        "        for parent in [base] + list(base.parents):\n",
        "            if (parent / \"verl\").exists():\n",
        "                REPO_ROOT = parent\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "        break\n",
        "\n",
        "train_path = REPO_ROOT / \"data\" / \"train_critique.parquet\"\n",
        "# verl 패키지를 로컬 경로에서 import할 수 있도록 추가\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "\n",
        "# reward 서버 환경 변수 (모듈 import 전에 설정)\n",
        "os.environ.setdefault(\"REWARD_PORT\", \"8000\")\n",
        "os.environ.setdefault(\"REWARD_API_URL\", f\"http://localhost:{os.environ['REWARD_PORT']}/v1\")\n",
        "os.environ.setdefault(\"REWARD_MODEL_NAME\", \"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "os.environ.setdefault(\"REWARD_MODEL_PATH\", os.environ[\"REWARD_MODEL_NAME\"])\n",
        "os.environ.setdefault(\"REWARD_TEMPERATURE\", \"0.6\")\n",
        "os.environ.setdefault(\"REWARD_TOP_P\", \"0.9\")\n",
        "os.environ.setdefault(\"REWARD_MAX_NEW_TOKENS\", \"2048\")\n",
        "os.environ.setdefault(\"REWARD_MAX_PROMPT_CHARS\", \"8192\")\n",
        "\n",
        "print(\"Repo root:\", REPO_ROOT)\n",
        "print(\"Train file:\", train_path)\n",
        "print(\"Reward API:\", os.environ[\"REWARD_API_URL\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00eab76",
      "metadata": {},
      "source": [
        "## Reward 서버(vLLM) 준비\n",
        "\n",
        "이미 vLLM 서버가 떠 있다면 이 셀을 건너뛰고 `START_SERVER=False`로 두세요. 새로 띄우려면 `START_SERVER=True`로 변경하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f285750b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching vLLM server... ['python3', '-m', 'vllm.entrypoints.openai.api_server', '--model', 'meta-llama/Llama-3.2-3B-Instruct', '--port', '8000', '--gpu-memory-utilization', '0.4', '--max-model-len', '10240', '--dtype', 'bfloat16', '--tensor-parallel-size', '1']\n",
            "Reward 서버가 준비되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "\n",
        "START_SERVER = True  # True 로 바꾸면 아래에서 vLLM 서버를 띄움\n",
        "reward_port = int(os.environ[\"REWARD_PORT\"])\n",
        "health_url = f\"http://localhost:{reward_port}/health\"\n",
        "reward_model = os.environ[\"REWARD_MODEL_NAME\"]\n",
        "reward_gpu = os.environ.get(\"REWARD_GPU_ID\", \"2\")\n",
        "server_proc = None\n",
        "\n",
        "if START_SERVER:\n",
        "    try:\n",
        "        requests.get(health_url, timeout=2).raise_for_status()\n",
        "        print(\"이미 reward 서버가 실행 중입니다.\")\n",
        "    except Exception:\n",
        "        cmd = [\n",
        "            \"python3\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n",
        "            \"--model\", reward_model,\n",
        "            \"--port\", str(reward_port),\n",
        "            \"--gpu-memory-utilization\", \"0.4\",\n",
        "            \"--max-model-len\", \"10240\",\n",
        "            \"--dtype\", \"bfloat16\",\n",
        "            \"--tensor-parallel-size\", \"1\",\n",
        "        ]\n",
        "        env = {**os.environ, \"CUDA_VISIBLE_DEVICES\": reward_gpu}\n",
        "        print(\"Launching vLLM server...\", cmd)\n",
        "        server_proc = subprocess.Popen(cmd, env=env, stdout=open(\"vllm_server.log\", \"w\"), stderr=subprocess.STDOUT)\n",
        "\n",
        "        for wait_s in range(0, 310, 5):\n",
        "            try:\n",
        "                requests.get(health_url, timeout=2).raise_for_status()\n",
        "                print(\"Reward 서버가 준비되었습니다.\")\n",
        "                break\n",
        "            except Exception:\n",
        "                time.sleep(5)\n",
        "        else:\n",
        "            raise RuntimeError(\"vLLM 서버가 시작되지 않았습니다. vllm_server.log를 확인하세요.\")\n",
        "else:\n",
        "    print(f\"START_SERVER=False -> 이미 떠 있는 http://localhost:{reward_port} 를 사용합니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e18f2f6",
      "metadata": {},
      "source": [
        "## 샘플 데이터 적재\n",
        "훈련/평가에 쓰인 critique 데이터에서 몇 개 샘플을 뽑습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aff323f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플 수: 1564\n",
            "         data_source\n",
            "0  critique_variants\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_parquet(\"/data1/home/yunhochoi/verl/data/train_critique.parquet\")\n",
        "print(\"전체 샘플 수:\", len(df))\n",
        "\n",
        "# 테스트용으로 N개만 사용\n",
        "N_SAMPLES = 1\n",
        "samples = df.sample(n=N_SAMPLES, random_state=0).reset_index(drop=True)\n",
        "# ground_truth는 reward_model['ground_truth'] 안에 JSON 문자열로 들어 있음\n",
        "print(samples[[\"data_source\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9954b18",
      "metadata": {},
      "source": [
        "## Qwen으로 critique 생성\n",
        "Qwen2.5-7B-Instruct를 로드해 각 샘플의 `prompt`(대화 형식)에 대해 critique을 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "036d3194",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0] critique (앞부분): The provided model solution trace is correct and logically sound. Let's break down the steps to ensure clarity and accuracy:\n",
            "\n",
            "1. **Identify the coefficients**:\n",
            "   - The quadratic equation is \\(8x^2 -  ...\n",
            "\n",
            "[Sample 0 / Variant 0] prompt_len=2240\n",
            "Q: What is the discriminant of $8x^2 - 48x + 69$?\n",
            "GT: 96\n",
            "preds: ['### Solution to the Variation Problem\\n\\nThe given quadratic equation is $8x^2 - 48x + 69$.\\n\\n**Step 1: Identify the coefficients**\\n- $a = 8$\\n- $b = -48$\\n- $c = 69$\\n\\n**Step 2: Apply the discriminant formula**\\n- The discriminant $\\\\Delta$ of a quadratic equation $ax^2 + bx + c$ is given by $\\\\Delta = b^2 - 4ac$.\\n\\n**Step 3: Substitute the values**\\n- Substitute $a = 8$, $b = -48$, and $c = 69$ into the formula:\\n  \\\\[\\n  \\\\Delta = (-48)^2 - 4 \\\\cdot 8 \\\\cdot 69\\n  \\\\]\\n\\n**Step 4: Calculate each part**\\n- Calculate $(-48)^2$:\\n  \\\\[\\n  (-48)^2 = 2304\\n  \\\\]\\n- Calculate $4 \\\\cdot 8 \\\\cdot 69$:\\n  \\\\[\\n  4 \\\\cdot 8 = 32\\n  \\\\]\\n  \\\\[\\n  32 \\\\cdot 69 = 2208\\n  \\\\]\\n\\n**Step 5: Subtract the results**\\n- Subtract $2208$ from $2304$:\\n  \\\\[\\n  2304 - 2208 = 96\\n  \\\\]\\n\\nThus, the discriminant of the quadratic equation $8x^2 - 48x + 69$ is indeed $\\\\boxed{96}$.']\n",
            "scores: [1.0]\n",
            "[Sample 0] final_score=1.0\n",
            "\n",
            "=== Sample 0 | final_score=1.0000\n",
            "- Variant: What is the discriminant of $8x^2 - 48x + 69$?\n",
            "  preds: ['### Solution to the Variation Problem\\n\\nThe given quadratic equation is $8x^2 - 48x + 69$.\\n\\n**Step 1: Identify the coefficients**\\n- $a = 8$\\n- $b = -48$\\n- $c = 69$\\n\\n**Step 2: Apply the discriminant formula**\\n- The discriminant $\\\\Delta$ of a quadratic equation $ax^2 + bx + c$ is given by $\\\\Delta = b^2 - 4ac$.\\n\\n**Step 3: Substitute the values**\\n- Substitute $a = 8$, $b = -48$, and $c = 69$ into the formula:\\n  \\\\[\\n  \\\\Delta = (-48)^2 - 4 \\\\cdot 8 \\\\cdot 69\\n  \\\\]\\n\\n**Step 4: Calculate each part**\\n- Calculate $(-48)^2$:\\n  \\\\[\\n  (-48)^2 = 2304\\n  \\\\]\\n- Calculate $4 \\\\cdot 8 \\\\cdot 69$:\\n  \\\\[\\n  4 \\\\cdot 8 = 32\\n  \\\\]\\n  \\\\[\\n  32 \\\\cdot 69 = 2208\\n  \\\\]\\n\\n**Step 5: Subtract the results**\\n- Subtract $2208$ from $2304$:\\n  \\\\[\\n  2304 - 2208 = 96\\n  \\\\]\\n\\nThus, the discriminant of the quadratic equation $8x^2 - 48x + 69$ is indeed $\\\\boxed{96}$.']\n",
            "  scores: [1.0]\n",
            "  variant_score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import json\n",
        "import os\n",
        "import asyncio\n",
        "# verl 관련 import는 사용자 환경에 맞춰 유지\n",
        "from verl.trainer.ppo.custom_rewards import critique_reward as cr\n",
        "from verl.utils.reward_score.math_verify import compute_score as mv_score\n",
        "\n",
        "# --- 설정 및 모델 로드 (기존과 동일) ---\n",
        "CRITIQUE_MODEL = os.environ.get(\"CRITIQUE_MODEL_PATH\", \"Qwen/Qwen2.5-7B-Instruct\")\n",
        "LOAD_QWEN = True  \n",
        "cr.NUM_REPEATS = 1\n",
        "N_SAMPLES = 1\n",
        "\n",
        "if LOAD_QWEN:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CRITIQUE_MODEL)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        CRITIQUE_MODEL,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "    )\n",
        "else:\n",
        "    tokenizer = model = None\n",
        "\n",
        "def generate_critique(messages, max_new_tokens=1024, temperature=0.7, top_p=0.9):\n",
        "    if tokenizer is None or model is None:\n",
        "        raise RuntimeError(\"LOAD_QWEN=True 로 설정하고 모델을 로드하세요.\")\n",
        "\n",
        "    prompt_text = tokenizer.apply_chat_template(\n",
        "        list(messages), tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    gen_ids = output[0][inputs[\"input_ids\"].shape[1]:]\n",
        "    generated = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "    return generated, prompt_text\n",
        "\n",
        "\n",
        "critique_payloads = []\n",
        "for i, row in samples.iterrows():\n",
        "    messages = list(row[\"prompt\"])  # numpy array -> list\n",
        "    critique_text, rendered_prompt = generate_critique(messages)\n",
        "    critique_payloads.append(\n",
        "        {\n",
        "            \"idx\": i,\n",
        "            \"messages\": messages,\n",
        "            \"critique\": critique_text,\n",
        "            \"rendered_prompt\": rendered_prompt,\n",
        "            \"ground_truth\": row[\"reward_model\"][\"ground_truth\"],\n",
        "        }\n",
        "    )\n",
        "    print(f\"[{i}] critique (앞부분):\", critique_text[:200], \"...\")\n",
        "\n",
        "samples = df.sample(n=N_SAMPLES, random_state=0).reset_index(drop=True)\n",
        "\n",
        "TARGET_VARIANT_IDX = 0\n",
        "\n",
        "\n",
        "# === [수정된 핵심 부분] ===\n",
        "def score_with_outputs(critique: str, ground_truth: str, sample_idx: int):\n",
        "    runner = cr._get_runner()\n",
        "\n",
        "    # 1. 비동기 함수: LLM 호출하여 '답변 텍스트'만 가져옴 (채점 X)\n",
        "    async def _inner_collect():\n",
        "        meta = json.loads(ground_truth)\n",
        "        original_q = meta.get(\"original_question\") or meta.get(\"question\", \"\")\n",
        "        original_traj = meta.get(\"original_trajectory\") or meta.get(\"trajectory\", \"\")\n",
        "        variants = meta.get(\"variants\", []) or []\n",
        "\n",
        "        if not variants:\n",
        "            return None\n",
        "\n",
        "        var = variants[TARGET_VARIANT_IDX]\n",
        "        var_q = var.get(\"q\") or var.get(\"question\")\n",
        "        var_a = var.get(\"a\") or var.get(\"answer\")\n",
        "        if not var_q or not var_a:\n",
        "            return None\n",
        "\n",
        "        sem = asyncio.Semaphore(cr.MAX_CONCURRENCY)\n",
        "        prompt = cr._build_prompt(original_q, original_traj, critique, var_q)\n",
        "        \n",
        "        print(f\"\\n[Sample {sample_idx} / Variant {TARGET_VARIANT_IDX}] prompt_len={len(prompt)}\")\n",
        "        print(\"Q:\", var_q)\n",
        "        print(\"GT:\", var_a)\n",
        "\n",
        "        # 여기서 LLM 호출 (백그라운드 스레드 OK)\n",
        "        preds = await cr._call_llama(runner.session, sem, prompt, n=1)\n",
        "        print(\"preds:\", preds)\n",
        "\n",
        "        # 채점하지 않고 데이터만 리턴\n",
        "        return {\n",
        "            \"var_q\": var_q,\n",
        "            \"var_a\": var_a,\n",
        "            \"preds\": preds\n",
        "        }\n",
        "\n",
        "    # 2. runner로 실행하여 결과 받아오기\n",
        "    # _inner_collect는 백그라운드 스레드에서 돌고, result는 여기서 받음\n",
        "    result_data = runner.run(_inner_collect())\n",
        "\n",
        "    # 3. 메인 스레드에서 채점 (mv_score) 수행\n",
        "    final_score = 0.0\n",
        "    details = []\n",
        "\n",
        "    if result_data:\n",
        "        var_q = result_data[\"var_q\"]\n",
        "        var_a = result_data[\"var_a\"]\n",
        "        preds = result_data[\"preds\"]\n",
        "        scores = []\n",
        "\n",
        "        if preds:\n",
        "            # 여기가 핵심: 메인 스레드에서 루프를 돌며 채점\n",
        "            scores = [mv_score(p, var_a) for p in preds]\n",
        "            print(\"scores:\", scores)\n",
        "            variant_score = sum(scores) / len(scores)\n",
        "            final_score = variant_score\n",
        "        else:\n",
        "            variant_score = None\n",
        "            final_score = 0.0\n",
        "\n",
        "        details = [{\n",
        "            \"question\": var_q,\n",
        "            \"answer\": var_a,\n",
        "            \"predictions\": preds,\n",
        "            \"scores\": scores,\n",
        "            \"variant_score\": variant_score,\n",
        "        }]\n",
        "    else:\n",
        "        # variants가 없거나 에러인 경우\n",
        "        details = [{\"error\": \"No variants or invalid data\"}]\n",
        "\n",
        "    print(f\"[Sample {sample_idx}] final_score={final_score}\\n\")\n",
        "    return {\"final_score\": final_score, \"details\": details}\n",
        "\n",
        "# 실행\n",
        "scored = []\n",
        "for payload in critique_payloads:\n",
        "    result = score_with_outputs(payload[\"critique\"], payload[\"ground_truth\"], payload[\"idx\"])\n",
        "    scored.append({**payload, **result})\n",
        "\n",
        "# 요약 출력\n",
        "for item in scored:\n",
        "    print(f\"=== Sample {item['idx']} | final_score={item['final_score']:.4f}\")\n",
        "    for d in item[\"details\"]:\n",
        "        print(f\"- Variant: {d['question']}\")\n",
        "        print(\"  preds:\", d[\"predictions\"])\n",
        "        print(\"  scores:\", d[\"scores\"])\n",
        "        print(\"  variant_score:\", d[\"variant_score\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import json\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import asyncio\n",
        "from verl.trainer.ppo.custom_rewards import critique_reward as cr\n",
        "from verl.utils.reward_score.math_verify import compute_score as mv_score\n",
        "\n",
        "CRITIQUE_MODEL = os.environ.get(\"CRITIQUE_MODEL_PATH\", \"Qwen/Qwen2.5-7B-Instruct\")\n",
        "LOAD_QWEN = True  \n",
        "cr.NUM_REPEATS = 1\n",
        "N_SAMPLES = 1\n",
        "\n",
        "if LOAD_QWEN:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CRITIQUE_MODEL)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        CRITIQUE_MODEL,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "    )\n",
        "else:\n",
        "    tokenizer = model = None\n",
        "\n",
        "\n",
        "def generate_critique(messages, max_new_tokens=1024, temperature=0.7, top_p=0.9):\n",
        "    '''주어진 메시지 리스트로 critique 텍스트를 생성합니다.'''\n",
        "    if tokenizer is None or model is None:\n",
        "        raise RuntimeError(\"LOAD_QWEN=True 로 설정하고 모델을 로드하세요.\")\n",
        "\n",
        "    prompt_text = tokenizer.apply_chat_template(\n",
        "        list(messages), tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    gen_ids = output[0][inputs[\"input_ids\"].shape[1]:]\n",
        "    generated = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "    return generated, prompt_text\n",
        "\n",
        "\n",
        "critique_payloads = []\n",
        "for i, row in samples.iterrows():\n",
        "    messages = list(row[\"prompt\"])  # numpy array -> list\n",
        "    critique_text, rendered_prompt = generate_critique(messages)\n",
        "    critique_payloads.append(\n",
        "        {\n",
        "            \"idx\": i,\n",
        "            \"messages\": messages,\n",
        "            \"critique\": critique_text,\n",
        "            \"rendered_prompt\": rendered_prompt,\n",
        "            \"ground_truth\": row[\"reward_model\"][\"ground_truth\"],\n",
        "        }\n",
        "    )\n",
        "    print(f\"[{i}] critique (앞부분):\", critique_text[:200], \"...\")\n",
        "\n",
        "samples = df.sample(n=N_SAMPLES, random_state=0).reset_index(drop=True)\n",
        "\n",
        "TARGET_VARIANT_IDX = 0\n",
        "\n",
        "def score_with_outputs(critique: str, ground_truth: str, sample_idx: int):\n",
        "    runner = cr._get_runner()\n",
        "\n",
        "    async def _inner():\n",
        "        meta = json.loads(ground_truth)\n",
        "        original_q = meta.get(\"original_question\") or meta.get(\"question\", \"\")\n",
        "        original_traj = meta.get(\"original_trajectory\") or meta.get(\"trajectory\", \"\")\n",
        "        variants = meta.get(\"variants\", []) or []\n",
        "\n",
        "        if not variants:\n",
        "            return {\"final_score\": 0.0, \"details\": []}\n",
        "\n",
        "        var = variants[TARGET_VARIANT_IDX]\n",
        "        var_q = var.get(\"q\") or var.get(\"question\")\n",
        "        var_a = var.get(\"a\") or var.get(\"answer\")\n",
        "        if not var_q or not var_a:\n",
        "            return {\"final_score\": 0.0, \"details\": []}\n",
        "\n",
        "        sem = asyncio.Semaphore(cr.MAX_CONCURRENCY)\n",
        "        prompt = cr._build_prompt(original_q, original_traj, critique, var_q)\n",
        "        print(f\"\\n[Sample {sample_idx} / Variant {TARGET_VARIANT_IDX}] prompt_len={len(prompt)}\")\n",
        "        print(\"Q:\", var_q)\n",
        "        print(\"GT:\", var_a)\n",
        "\n",
        "        preds = await cr._call_llama(runner.session, sem, prompt, n=1)\n",
        "        print(\"preds:\", preds)\n",
        "\n",
        "        if preds:\n",
        "            scores = [mv_score(p, var_a) for p in preds]\n",
        "            print(\"scores:\", scores)\n",
        "            variant_score = sum(scores) / len(scores)\n",
        "            final_score = variant_score\n",
        "        else:\n",
        "            scores = []\n",
        "            variant_score = None\n",
        "            final_score = 0.0\n",
        "\n",
        "        details = [{\n",
        "            \"question\": var_q,\n",
        "            \"answer\": var_a,\n",
        "            \"predictions\": preds,\n",
        "            \"scores\": scores,\n",
        "            \"variant_score\": variant_score,\n",
        "        }]\n",
        "        print(f\"[Sample {sample_idx}] final_score={final_score}\\n\")\n",
        "        return {\"final_score\": final_score, \"details\": details}\n",
        "\n",
        "    return runner.run(_inner())\n",
        "\n",
        "# 실행\n",
        "scored = []\n",
        "for payload in critique_payloads:\n",
        "    result = score_with_outputs(payload[\"critique\"], payload[\"ground_truth\"], payload[\"idx\"])\n",
        "    scored.append({**payload, **result})\n",
        "\n",
        "# 요약 출력\n",
        "for item in scored:\n",
        "    print(f\"=== Sample {item['idx']} | final_score={item['final_score']:.4f}\")\n",
        "    for d in item[\"details\"]:\n",
        "        print(f\"- Variant: {d['question']}\")\n",
        "        print(\"  preds:\", d[\"predictions\"])\n",
        "        print(\"  scores:\", d[\"scores\"])\n",
        "        print(\"  variant_score:\", d[\"variant_score\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e88acf87",
      "metadata": {},
      "outputs": [],
      "source": [
        "cr.NUM_REPEATS = 1 \n",
        "\n",
        "runner = cr._get_runner()\n",
        "meta = json.loads(row[\"reward_model\"][\"ground_truth\"])\n",
        "original_q = meta[\"original_question\"]\n",
        "original_traj = meta[\"original_trajectory\"]\n",
        "var = meta[\"variants\"][0]\n",
        "var_q = var.get(\"q\") or var.get(\"question\")\n",
        "var_a = var.get(\"a\") or var.get(\"answer\")\n",
        "\n",
        "prompt = cr._build_prompt(original_q, original_traj, critique_payloads[0][\"critique\"], var_q)\n",
        "print(\"prompt length:\", len(prompt))\n",
        "print(\"prompt preview:\\n\", prompt, \"...\")\n",
        "\n",
        "preds = runner.run(cr._call_llama(runner.session, asyncio.Semaphore(cr.MAX_CONCURRENCY), prompt, n=1))\n",
        "print(\"preds:\", preds)\n",
        "\n",
        "print(\"GT(answer):\", var_a)\n",
        "for i, p in enumerate(preds):\n",
        "    s = mv_score(p, var_a)\n",
        "    print(f\"[{i}] score={s:.4f} pred preview:\", p[:300], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea0db984",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'original_question': 'What is the discriminant of $8x^2 - 48x + 69$?', 'original_trajectory': 'The discriminant of a quadratic equation in the form $ax^2 + bx + c$ is given by the formula $b^2 - 4ac$.\\n\\nFor the given quadratic equation $8x^2 - 48x + 69$, we have:\\n\\n$a = 8$\\n$b = -48$\\n$c = 69$\\n\\nNow, we can plug these values into the formula for the discriminant:\\n\\n$b^2 - 4ac = (-48)^2 - 4(8)(69)$\\n= 2304 - 2208\\n= 96\\n\\nTherefore, the discriminant of $8x^2 - 48x + 69$ is 96.', 'variants': [{'snapshot': 'Oct-2023', 'question': 'What is the discriminant of $8x^2 - 48x + 69$?', 'answer': '96'}, {'snapshot': 'Nov-2023', 'question': 'What is the discriminant of $4x^2 - 66x + 81$?', 'answer': '3060'}, {'snapshot': 'Dec-2023', 'question': 'What is the discriminant of $2x^2 - 81x + 39$?', 'answer': '6249'}]}\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
            "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
            "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
            "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
          ]
        }
      ],
      "source": [
        "meta = json.loads(row[\"reward_model\"][\"ground_truth\"])\n",
        "print(meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9648f5af",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3139fa47",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## vLLM 서버 정리 (옵션)\n",
        "노트북에서 서버를 띄웠다면 종료합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vLLM reward 서버를 종료했습니다.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
            "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
            "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
            "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
          ]
        }
      ],
      "source": [
        "if server_proc:\n",
        "    server_proc.terminate()\n",
        "    server_proc.wait()\n",
        "    print(\"vLLM reward 서버를 종료했습니다.\")\n",
        "else:\n",
        "    print(\"별도 종료할 서버가 없습니다.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "verl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
